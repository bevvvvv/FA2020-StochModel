---
title: "Homework 07 - STAT416"
author: "Joseph Sepich (jps6444)"
date: "10/27/2020"
output:
  pdf_document:
    number_sections: false
---

```{r include=FALSE}
library(dplyr)
```

# Chapter 4 Problem 19

We want to calculate the proportion of days that it rains.

To determine the proportion of days that it rains we can calculate the proportion of time spent in each state, and then use the probability of it raining to determine the proportion of time it rains. This gives us our system of equations:

\[\pi_0 = 0.7\pi_0+0.5\pi_1\]
\[\pi_1 = 0.4\pi_2+0.2\pi_3\]
\[\pi_2 = 0.3\pi_0+0.5\pi_1\]
\[\pi_3 = 0.6\pi_2+0.8\pi_3\]
\[\pi_0+\pi_1+\pi_2+\pi_3 = 1\]

We can solve this system of equations through linear algebra:

```{r}
pi_0 <- c(-0.3,0,0.3,1)
pi_1 <- c(0.5,-1,0.5,1)
pi_2 <- c(0,0.4,-1,1)
pi_3 <- c(0,0.2,0,1)
A <- cbind(pi_0, pi_1, pi_2, pi_3)
b <- c(0,0,0,1)
solve(A,b)
```

We can then use the two states where it rained today (0 and 1) to calculate:

\[\pi_R = \pi_0 + \pi_1 = 0.25 + 0.15 = 0.4 = \frac25\]

It rains about 40% of the days in this random process.

# Chapter 4 Problem 25

To determine the proportion of the time that the runner leaves the house barefooted we must first determine our Markov chain. Clearly the states in this problem dictate where the shoes are placed. Given k shoes we have the states $(x,y)$ where $x + y = k$, so we have a total of k+1 states: $(k, 0), (k-1, 1) ... (0, k)$. We can also phrase the states concisely in four:

1. Running with shoes and left from the front.
2. Running barefooted and left from the front.
3. Running with shoes and left from the back.
4. Running barefooted and left from the back.

Consider the first state. If the runner left with shoes and left from the front door, then the next time they leave from the front there are k states in which they leave with shoes. The same logic follows for the back.

This would give us the probability transition matrix:

$$
P =\begin{bmatrix}
\frac{k}{k+1}  & \frac1{k+1} & 0 & 0\\
\frac{k}{k+1}  & \frac1{k+1} & 0 & 0 \\
0 & 0 & \frac{k}{k+1}  & \frac1{k+1} \\
0 & 0 & \frac{k}{k+1}  & \frac1{k+1}
\end{bmatrix}
$$

This gives us the equations:

\[\pi_0 = \frac{k}{k+1}\pi_0 + \frac{k}{k+1}\pi_1\]
\[\pi_1 = \frac{1}{k+1}\pi_0 + \frac{1}{k+1}\pi_1\]
\[\pi_2 = \frac{k}{k+1}\pi_2 + \frac{k}{k+1}\pi_3\]
\[\pi_3 = \frac{1}{k+1}\pi_2 + \frac{1}{k+1}\pi_3\]
\[\pi_0 + \pi_1 + \pi_2 + \pi_3 = 1\]

Solving this system of equations we get that the runner will leave barefooted 1 out of every k times.

# Chapter 4 Problem 29

To find the percentage of employees in each classification we find the long run proportion of time spent in each of the three states.

\[\pi_0 = 0.7\pi_0 + 0.2\pi_1 + 0.1\pi_2\]
\[\pi_1 = 0.2\pi_0 + 0.6\pi_1 + 0.4\pi_2\]
\[\pi_2 = 0.1\pi_0 + 0.2\pi_1 + 0.5\pi_2\]
\[\pi_0 + \pi_1 + \pi_2 = 1\]

```{r}
pi_0 <- c(-0.3,0.2,1)
pi_1 <- c(0.2,-0.4,1)
pi_2 <- c(0.1,0.4,1)
A <- cbind(pi_0, pi_1, pi_2)
b <- c(0,0,1)
solve(A,b)
```

35.29% of employees are in the first classification, 41.18% are in the second classification, and 23.523% are in the third classification.

# Chapter 4 Problem 30

The probability of seeing a car given that we see a truck is $\frac34$. The probability of seeing a truck given that we see a car is $\frac15$. The proportion of trucks we see is therefore the fraction of vehicles on the road that are trucks.

\[\pi_C = \frac45\pi_C + \frac34\pi_T\]
\[\pi_T = \frac15\pi_C + \frac14\pi_T\]
\[\pi_C + \pi_T = 1\]

```{r}
pi_c <- c(-1/5,1)
pi_t <- c(3/4,1)
A <- cbind(pi_c, pi_t)
b <- c(0,1)
solve(A,b)
```

Solving the system we get that 4 out of every 19 vehicles on the road are trucks.

# Chapter 4 Problem 37

Recall that stationary probabilities are the long run proportions in remaining in a certain state. This proportion can be denoted as a limiting probability:

\[\pi_j = lim_{n\rightarrow\infty} P_{ij}^n\]

If $Q_{ij}$ is defined as the $k^{th}$ transitional probability of P, then it must have the same stationary probabilties. You can see this via the limit on the stationary probabilities of $Q_{ij}$:

\[\pi_j = lim_{n\rightarrow\infty} Q_{ij}^n = lim_{n\rightarrow\infty} (P_{ij}^k)^n = lim_{n\rightarrow\infty} P_{ij}^{kn}\]

The limit here is clearly again the long run probability of P, which is the same value we had before, so the stationary probabilities for both Markov chains, must be the same.

# Chapter 4 Problem 42

## Part a

\[\Sigma_{i\in A}\Sigma_{j\in A^c}\pi_iP_{ij}\]

There are two parts to the statement above. The first part of the statement is the proportion of time spent in set A. The second part of the statement is the  probability of transitioning from the given state in A to a certain state not in A. When you sum this values together you get the proportion of time spent transitioning into the set $A^c$ from A.

## Part b

\[\Sigma_{i\in A^c}\Sigma_{j\in A}\pi_iP_{ij}\]

The difference between this statement and the previous statement is that the proportion term relates to the state $A^c$ and the transition probability term relates to transitioning from $A^c$ to A. Therefore we are looking at a reverse of the previous statement, so this statement represents the proportion of time spent transitioning into the set A from $A^c$.

## Part c

As per our previous two interpretations, we would conclude that this identity states that the proportion of time spent transitioning from set A to $A^c$ is equal to the proportion of time spent transitioning from set $A^c$ to A. If the value were zero for example, then the two sets do not communicate. If this equality were say for example $\frac12$ on the other hand, we could conclude that the process is flipping between states in each set.

We basically have one rate saying how often we flip between A and $A^c$.

# Chapter 4 Problem 67

## Part a

## Part b

## Part c

## Part d

## Part e

## Part f











---
title: "Homework 07 - STAT416"
author: "Joseph Sepich (jps6444)"
date: "10/27/2020"
output:
  pdf_document:
    number_sections: false
---

```{r include=FALSE}
library(dplyr)
```

# Chapter 4 Problem 19

We want to calculate the proportion of days that it rains.

To determine the proportion of days that it rains we can calculate the proportion of time spent in each state, and then use the probability of it raining to determine the proportion of time it rains. This gives us our system of equations:

\[\pi_0 = 0.7\pi_0+0.5\pi_1\]
\[\pi_1 = 0.4\pi_2+0.2\pi_3\]
\[\pi_2 = 0.3\pi_0+0.5\pi_1\]
\[\pi_3 = 0.6\pi_2+0.8\pi_3\]
\[\pi_0+\pi_1+\pi_2+\pi_3 = 1\]

We can solve this system of equations through linear algebra:

```{r}
pi_0 <- c(-0.3,0,0.3,1)
pi_1 <- c(0.5,-1,0.5,1)
pi_2 <- c(0,0.4,-1,1)
pi_3 <- c(0,0.2,0,1)
A <- cbind(pi_0, pi_1, pi_2, pi_3)
b <- c(0,0,0,1)
solve(A,b)
```

We can then use the two states where it rained today (0 and 1) to calculate:

\[\pi_R = \pi_0 + \pi_1 = 0.25 + 0.15 = 0.4 = \frac25\]

It rains about 40% of the days in this random process.

# Chapter 4 Problem 25

To determine the proportion of the time that the runner leaves the house barefooted we must first determine our Markov chain. Clearly the states in this problem dictate where the shoes are placed. Given k shoes we have the states $(x,y)$ where $x + y = k$, so we have a total of k+1 states: $(k, 0), (k-1, 1) ... (0, k)$. We can also phrase the states concisely in four:

1. Running with shoes and left from the front.
2. Running barefooted and left from the front.
3. Running with shoes and left from the back.
4. Running barefooted and left from the back.

Consider the first state. If the runner left with shoes and left from the front door, then the next time they leave from the front there are k states in which they leave with shoes. The same logic follows for the back.

This would give us the probability transition matrix:

$$
P =\begin{bmatrix}
\frac{k}{k+1}  & \frac1{k+1} & 0 & 0\\
\frac{k}{k+1}  & \frac1{k+1} & 0 & 0 \\
0 & 0 & \frac{k}{k+1}  & \frac1{k+1} \\
0 & 0 & \frac{k}{k+1}  & \frac1{k+1}
\end{bmatrix}
$$

This gives us the equations:

\[\pi_0 = \frac{k}{k+1}\pi_0 + \frac{k}{k+1}\pi_1\]
\[\pi_1 = \frac{1}{k+1}\pi_0 + \frac{1}{k+1}\pi_1\]
\[\pi_2 = \frac{k}{k+1}\pi_2 + \frac{k}{k+1}\pi_3\]
\[\pi_3 = \frac{1}{k+1}\pi_2 + \frac{1}{k+1}\pi_3\]
\[\pi_0 + \pi_1 + \pi_2 + \pi_3 = 1\]

Solving this system of equations we get that the runner will leave barefooted 1 out of every k times.

# Chapter 4 Problem 29

To find the percentage of employees in each classification we find the long run proportion of time spent in each of the three states.

\[\pi_0 = 0.7\pi_0 + 0.2\pi_1 + 0.1\pi_2\]
\[\pi_1 = 0.2\pi_0 + 0.6\pi_1 + 0.4\pi_2\]
\[\pi_2 = 0.1\pi_0 + 0.2\pi_1 + 0.5\pi_2\]
\[\pi_0 + \pi_1 + \pi_2 = 1\]

```{r}
pi_0 <- c(-0.3,0.2,1)
pi_1 <- c(0.2,-0.4,1)
pi_2 <- c(0.1,0.4,1)
A <- cbind(pi_0, pi_1, pi_2)
b <- c(0,0,1)
solve(A,b)
```

35.29% of employees are in the first classification, 41.18% are in the second classification, and 23.523% are in the third classification.

# Chapter 4 Problem 30

The probability of seeing a car given that we see a truck is $\frac34$. The probability of seeing a truck given that we see a car is $\frac15$. The proportion of trucks we see is therefore the fraction of vehicles on the road that are trucks.

\[\pi_C = \frac45\pi_C + \frac34\pi_T\]
\[\pi_T = \frac15\pi_C + \frac14\pi_T\]
\[\pi_C + \pi_T = 1\]

```{r}
pi_c <- c(-1/5,1)
pi_t <- c(3/4,1)
A <- cbind(pi_c, pi_t)
b <- c(0,1)
solve(A,b)
```

Solving the system we get that 4 out of every 19 vehicles on the road are trucks.

# Chapter 4 Problem 37

Recall that stationary probabilities are the long run proportions in remaining in a certain state. This proportion can be denoted as a limiting probability:

\[\pi_j = lim_{n\rightarrow\infty} P_{ij}^n\]

If $Q_{ij}$ is defined as the $k^{th}$ transitional probability of P, then it must have the same stationary probabilties. You can see this via the limit on the stationary probabilities of $Q_{ij}$:

\[\pi_j = lim_{n\rightarrow\infty} Q_{ij}^n = lim_{n\rightarrow\infty} (P_{ij}^k)^n = lim_{n\rightarrow\infty} P_{ij}^{kn}\]

The limit here is clearly again the long run probability of P, which is the same value we had before, so the stationary probabilities for both Markov chains, must be the same.

# Chapter 4 Problem 42

## Part a

\[\Sigma_{i\in A}\Sigma_{j\in A^c}\pi_iP_{ij}\]

There are two parts to the statement above. The first part of the statement is the proportion of time spent in set A. The second part of the statement is the  probability of transitioning from the given state in A to a certain state not in A. When you sum this values together you get the proportion of time spent transitioning into the set $A^c$ from A.

## Part b

\[\Sigma_{i\in A^c}\Sigma_{j\in A}\pi_iP_{ij}\]

The difference between this statement and the previous statement is that the proportion term relates to the state $A^c$ and the transition probability term relates to transitioning from $A^c$ to A. Therefore we are looking at a reverse of the previous statement, so this statement represents the proportion of time spent transitioning into the set A from $A^c$.

## Part c

As per our previous two interpretations, we would conclude that this identity states that the proportion of time spent transitioning from set A to $A^c$ is equal to the proportion of time spent transitioning from set $A^c$ to A. If the value were zero for example, then the two sets do not communicate. If this equality were say for example $\frac12$ on the other hand, we could conclude that the process is flipping between states in each set.

We basically have one rate saying how often we flip between A and $A^c$.

# Chapter 4 Problem 67

Constraints

* Urn contains N balls
* White and Black balls
* Coin with prob p of heads
* Heads -> replace random ball with white
* Tails -> replace random ball with black

Say $X_n$ denotes number of white balls in the urn at stage n.

## Part a

The proposed Markov chain is indeed a Markov chain. The states were denoted as the number of white balls in the urn at stage n. This amount depends on two factors: the previous number of white balls (previous state) and the coin flip/ball drawn. The previous number of white balls is contained within the state and the coin flip/ball drawn follows the same procedure at each state, so it does not depend on the current/previous states. Therefore we satisfy the Markov property, because the value of the current state depends only on the previous state.

## Part b

The Markov chain has a single recurrent class. The period is 1, since if there are x white balls, a heads is flipped and then one of the x white balls is chosen, we end in the same state x. Since the transition probability $P_{ii} > 0$ the gcd of possible paths must be 1. This makes the chain aperiodic. These statements only hold true, because the probability of the coin flip of heads cannot be 0 or 1.

## Part c

The chain has N+1 states. If x denotes the number of white balls we then have the states $N, N-1, ... 0$, since $x + y = N$. At time $i$ we have either subtract one white, stay at the same number of whites, or increase the number of whites by one.

The first case happens when we draw a white and replace it with a black. This occurs with probability $P(x-1_{i+1}|x_i) =  \frac{x}{N}* (1-p)$. The second case happens when we draw a white or black ball, then replace it with the same type. This happens with probability $P(x_{i+1}|x_i) = \frac{x}{N} * p + \frac{N-x}{N} * (1-p)$. Finally the third case happens when we draw a black and replace it with a white. This happens with probability $P(X+1_{i+1}|x_i) = \frac{N-x}{N} * p$.

## Part d

Let's show the transition probability matrix for N=2, where we have three states: 0, 1, 2.

\[P_{11} = \frac12p + \frac12(1-p) = \frac12p-\frac12p+\frac12 = \frac12\]

$$
P =\begin{bmatrix}
1-p & p & 0 \\
\frac{1-p}{2} & \frac12 & \frac{p}{2} \\
0 & 1-p & p 
\end{bmatrix}
$$

Now we can find the proportion of time in each state by setting up our system of equations:

\[\pi_0 = (1-p)\pi_0 + \frac{1-p}{2}\pi_1\]
\[\pi_1 = p\pi_0 + \frac12\pi_1 + (1-p)\pi_2\]
\[\pi_2 = \frac{p}{2}\pi_1 + p\pi_2\]
\[\pi_0 + \pi_1 + \pi_2 = 1\]

Start with equation 1:

\[0 = -p\pi_0 + \frac{1-p}{2}\pi_1\]
\[\pi_0 = \frac{1-p}{2p}\pi_1\]

Next we use equation 3:

\[(1-p)\pi_2 = \frac{p}{2}\pi_1\]
\[\pi_2 = \frac{p}{2-2p}\pi_1\]

Plug into equation 4:

\[\frac{1-p}{2p}\pi_1 + \pi_1 + \frac{p}{2(1-p)}\pi_1 = 1\]
\[\frac{(1-p)^2}{2p(1-p)}\pi_1 + \frac{2p(1-p)}{2p(1-p)}\pi_1 + \frac{p^2}{2p(1-p)}\pi_1 = 1\]
\[\frac{(1-p)^2 + 2p(1-p) + p^2}{2p(1-p)}\pi_1 = 1\]

The top part of the fraction is a typical product of a squared term:

\[\frac{(p+1-p)^2}{2p(1-p)}\pi_1 = 1\]
\[\pi_1 = 2p(1-p)\]

Now we can plug back in to get the other two propotions:

\[\pi_0 = \frac{1-p}{2p}(2p(1-p)) = (1-p)^2\]
\[\pi_2 = \frac{p}{2-2p}(2p(1-p)) = p^2\]

In summary the proportion of time spent with zero white balls in the urn is $(1-p)^2$, the proportion of time spent with 1 white ball in the urn is $2p(1-p)$ and the proportion of time spent with 2 white balls in the urn is $p^2$.

## Part e

In the general case I would expect the stationary probabilities to be $\binom{n}{i}p^{i}(1-p)^{n-i}$ for the $i^{th}$ state where $i$ ranges from 0 to $n$. The first part is how many ways the following balls are chosen, and I just pattern matched the other two terms.

## Part f

For these guesses to work, we must show they satisfy two conditions:

\[\pi_j = \Sigma_i\pi_iP_{ij}\]
\[\Sigma_j\pi_j = 1\]

Let's look at the second condition first. We can use the summation of a binomial series to get our answer.

\[\Sigma_{j=0}^n \binom{n}{i}p^{i}(1-p)^{n-i} = (p + 1 - p)^n = 1^n = 1\]

For the first condition we look at state x.

\[\pi_x = \pi_{x-1}P_{x-1,x} + \pi_xP_{x,x} + \pi_{x+1}P_{x+1,x}\]

We can plug in the transition probabilites from part c and our proposed stationary equation. Let's do look at each term:

\[\pi_x = \binom{n}{x}p^{x}(1-p)^{n-x}\]
\[\pi_{x-1}P_{x-1,x} = \binom{n}{x-1}p^{x-1}(1-p)^{n-x+1}\frac{p(n-x+1)}{n}\]
\[\pi_{x}P_{x,x} = \binom{n}{x}p^{x}(1-p)^{n-x}(\frac{px}{n} + \frac{(1-p)(n-x}{n})\]
\[\pi_{x+1}P_{x+1,x} = \binom{n}{x+1}p^{x+1}(1-p)^{n-x-1}(\frac{(1-p)x}{n})\]

Adding these together we get:

\[\binom{n}{x}p^{x}(1-p)^{n-x} = \binom{n}{x-1}p^{x-1}(1-p)^{n-x+1}\frac{p(n-x+1)}{n} + \binom{n}{x}p^{x}(1-p)^{n-x}(\frac{px}{n} + \frac{(1-p)(n-x}{n}) + \binom{n}{x+1}p^{x+1}(1-p)^{n-x-1}(\frac{(1-p)x}{n})\]











